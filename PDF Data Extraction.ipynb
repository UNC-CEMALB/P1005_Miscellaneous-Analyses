{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c2ce97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.2 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.6      \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.8      \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.10\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.1      \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.1 \n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.2      \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.2 \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "Using poppler version 22.02.0\n",
      "\n",
      "Loading required package: NLP\n",
      "\n",
      "\n",
      "Attaching package: ‘NLP’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    annotate\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'20221213_0004_18F6_80_size_488.pdf'</li><li>'20221213_0005_18F6_90_size_488.pdf'</li><li>'20221213_0006_18F6_70_size_488.pdf'</li><li>'20221213_0007_18F7_70_size_488.pdf'</li><li>'20221213_0008_18F7_80_size_488.pdf'</li><li>'20221213_0009_18F7_89_size_488.pdf'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '20221213\\_0004\\_18F6\\_80\\_size\\_488.pdf'\n",
       "\\item '20221213\\_0005\\_18F6\\_90\\_size\\_488.pdf'\n",
       "\\item '20221213\\_0006\\_18F6\\_70\\_size\\_488.pdf'\n",
       "\\item '20221213\\_0007\\_18F7\\_70\\_size\\_488.pdf'\n",
       "\\item '20221213\\_0008\\_18F7\\_80\\_size\\_488.pdf'\n",
       "\\item '20221213\\_0009\\_18F7\\_89\\_size\\_488.pdf'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '20221213_0004_18F6_80_size_488.pdf'\n",
       "2. '20221213_0005_18F6_90_size_488.pdf'\n",
       "3. '20221213_0006_18F6_70_size_488.pdf'\n",
       "4. '20221213_0007_18F7_70_size_488.pdf'\n",
       "5. '20221213_0008_18F7_80_size_488.pdf'\n",
       "6. '20221213_0009_18F7_89_size_488.pdf'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"20221213_0004_18F6_80_size_488.pdf\" \"20221213_0005_18F6_90_size_488.pdf\"\n",
       "[3] \"20221213_0006_18F6_70_size_488.pdf\" \"20221213_0007_18F7_70_size_488.pdf\"\n",
       "[5] \"20221213_0008_18F7_80_size_488.pdf\" \"20221213_0009_18F7_89_size_488.pdf\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "setwd(\"/Users/alexis/Library/CloudStorage/OneDrive-UniversityofNorthCarolinaatChapelHill/CEMALB_DataAnalysisPM/Projects/P1005. Miscellaneous Analyses/P1005.4. Clinical Sample EVs/P1005.4.2. Analyses/Input\")\n",
    "Output = (\"/Users/alexis/Library/CloudStorage/OneDrive-UniversityofNorthCarolinaatChapelHill/CEMALB_DataAnalysisPM/Projects/P1005. Miscellaneous Analyses/P1005.4. Clinical Sample EVs/P1005.4.2. Analyses/Output\")\n",
    "\n",
    "cur_date = \"121522\"\n",
    "\n",
    "library(tidyverse)\n",
    "library(pdftools)\n",
    "library(tm)\n",
    "\n",
    "# only grabs files ending in \"pdf\"\n",
    "pdf_list = list.files(pattern = \"pdf$\")\n",
    "head(pdf_list)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a030a3d1",
   "metadata": {},
   "source": [
    "# Data we want to extract:\n",
    "1. Pdf file name as the sample identifier\n",
    "2. Original Concentration\n",
    "3. Some of the ‘X Values’ table listed on the bottom left, specifically the: X10 Concentration, X50 Concentration, X90 Concentration, and Mean Concentration, and StdDev Concentration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b6572e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n",
      "PDF error: Invalid least number of objects reading page offset hints table\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this code I pulled online and I'm not entirely sure how each line of code works, but it just parses the pdf files\n",
    "corpus_raw <- data.frame(\"Sample Identifier\" = c(), \"Text\" = c())\n",
    "\n",
    "for (i in 1:length(pdf_list)){\n",
    "    document_text = pdf_text(paste(pdf_list[i],sep = \"\")) %>% \n",
    "    strsplit(\"\\n\")\n",
    "    \n",
    "        document = data.frame(\"Sample Identifier\" = gsub(x = pdf_list[i], pattern = \".pdf\", replacement = \"\"), \n",
    "        \"Text\" = document_text, stringsAsFactors = FALSE)\n",
    "    \n",
    "    colnames(document) <- c(\"Sample Identifier\", \"Text\")\n",
    "    corpus_raw <- rbind(corpus_raw,document) \n",
    "}\n",
    "\n",
    "# still haven't figured out why there are duplicates\n",
    "corpus_raw = unique(corpus_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6c5ed06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Sample Identifier</th><th scope=col>Text</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>20221213_0004_18F6_80_size_488</td><td><span style=white-space:pre-wrap>                                                                                                    Electrophoresis &amp; Brownian Motion</span></td></tr>\n",
       "\t<tr><th scope=row>2</th><td>20221213_0004_18F6_80_size_488</td><td>                                                                                                              Video Analysis         </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>20221213_0004_18F6_80_size_488</td><td>                                                                                                       Laser Scattering Microscopy   </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>20221213_0004_18F6_80_size_488</td><td>                                           www.particle-metrix.de                                                                    </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>20221213_0004_18F6_80_size_488</td><td>                                                                                                                                     </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>20221213_0004_18F6_80_size_488</td><td>                                                                                      Operator (Report): sop_kabanovlab.inst         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & Sample Identifier & Text\\\\\n",
       "  & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 20221213\\_0004\\_18F6\\_80\\_size\\_488 &                                                                                                     Electrophoresis \\& Brownian Motion\\\\\n",
       "\t2 & 20221213\\_0004\\_18F6\\_80\\_size\\_488 &                                                                                                               Video Analysis         \\\\\n",
       "\t3 & 20221213\\_0004\\_18F6\\_80\\_size\\_488 &                                                                                                        Laser Scattering Microscopy   \\\\\n",
       "\t4 & 20221213\\_0004\\_18F6\\_80\\_size\\_488 &                                            www.particle-metrix.de                                                                    \\\\\n",
       "\t5 & 20221213\\_0004\\_18F6\\_80\\_size\\_488 &                                                                                                                                      \\\\\n",
       "\t6 & 20221213\\_0004\\_18F6\\_80\\_size\\_488 &                                                                                       Operator (Report): sop\\_kabanovlab.inst         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | Sample Identifier &lt;chr&gt; | Text &lt;chr&gt; |\n",
       "|---|---|---|\n",
       "| 1 | 20221213_0004_18F6_80_size_488 |                                                                                                     Electrophoresis &amp; Brownian Motion |\n",
       "| 2 | 20221213_0004_18F6_80_size_488 |                                                                                                               Video Analysis          |\n",
       "| 3 | 20221213_0004_18F6_80_size_488 |                                                                                                        Laser Scattering Microscopy    |\n",
       "| 4 | 20221213_0004_18F6_80_size_488 |                                            www.particle-metrix.de                                                                     |\n",
       "| 5 | 20221213_0004_18F6_80_size_488 | <!----> |\n",
       "| 6 | 20221213_0004_18F6_80_size_488 |                                                                                       Operator (Report): sop_kabanovlab.inst          |\n",
       "\n"
      ],
      "text/plain": [
       "  Sample Identifier             \n",
       "1 20221213_0004_18F6_80_size_488\n",
       "2 20221213_0004_18F6_80_size_488\n",
       "3 20221213_0004_18F6_80_size_488\n",
       "4 20221213_0004_18F6_80_size_488\n",
       "5 20221213_0004_18F6_80_size_488\n",
       "6 20221213_0004_18F6_80_size_488\n",
       "  Text                                                                                                                                 \n",
       "1                                                                                                     Electrophoresis & Brownian Motion\n",
       "2                                                                                                               Video Analysis         \n",
       "3                                                                                                        Laser Scattering Microscopy   \n",
       "4                                            www.particle-metrix.de                                                                    \n",
       "5                                                                                                                                      \n",
       "6                                                                                       Operator (Report): sop_kabanovlab.inst         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# viewing data\n",
    "# dataframe contains a sample identifier column and a text column\n",
    "# sample identifier column: name of pdf file\n",
    "# text column: includes data/ text from the pdf\n",
    "head(corpus_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffc92849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Sample Identifier</th><th scope=col>Original Concentration (Particles/ mL)</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>20221213_0004_18F6_80_size_488</td><td>       3.1E+11 </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>20221213_0005_18F6_90_size_488</td><td>       1.1E+12 </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>20221213_0006_18F6_70_size_488</td><td>       1.3E+11 </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>20221213_0007_18F7_70_size_488</td><td>       4.4E+10 </td></tr>\n",
       "\t<tr><th scope=row>5</th><td>20221213_0008_18F7_80_size_488</td><td>       1.9E+11 </td></tr>\n",
       "\t<tr><th scope=row>6</th><td>20221213_0009_18F7_89_size_488</td><td>       7.3E+11 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 2\n",
       "\\begin{tabular}{r|ll}\n",
       "  & Sample Identifier & Original Concentration (Particles/ mL)\\\\\n",
       "  & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 20221213\\_0004\\_18F6\\_80\\_size\\_488 &        3.1E+11 \\\\\n",
       "\t2 & 20221213\\_0005\\_18F6\\_90\\_size\\_488 &        1.1E+12 \\\\\n",
       "\t3 & 20221213\\_0006\\_18F6\\_70\\_size\\_488 &        1.3E+11 \\\\\n",
       "\t4 & 20221213\\_0007\\_18F7\\_70\\_size\\_488 &        4.4E+10 \\\\\n",
       "\t5 & 20221213\\_0008\\_18F7\\_80\\_size\\_488 &        1.9E+11 \\\\\n",
       "\t6 & 20221213\\_0009\\_18F7\\_89\\_size\\_488 &        7.3E+11 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 2\n",
       "\n",
       "| <!--/--> | Sample Identifier &lt;chr&gt; | Original Concentration (Particles/ mL) &lt;chr&gt; |\n",
       "|---|---|---|\n",
       "| 1 | 20221213_0004_18F6_80_size_488 |        3.1E+11  |\n",
       "| 2 | 20221213_0005_18F6_90_size_488 |        1.1E+12  |\n",
       "| 3 | 20221213_0006_18F6_70_size_488 |        1.3E+11  |\n",
       "| 4 | 20221213_0007_18F7_70_size_488 |        4.4E+10  |\n",
       "| 5 | 20221213_0008_18F7_80_size_488 |        1.9E+11  |\n",
       "| 6 | 20221213_0009_18F7_89_size_488 |        7.3E+11  |\n",
       "\n"
      ],
      "text/plain": [
       "  Sample Identifier              Original Concentration (Particles/ mL)\n",
       "1 20221213_0004_18F6_80_size_488        3.1E+11                        \n",
       "2 20221213_0005_18F6_90_size_488        1.1E+12                        \n",
       "3 20221213_0006_18F6_70_size_488        1.3E+11                        \n",
       "4 20221213_0007_18F7_70_size_488        4.4E+10                        \n",
       "5 20221213_0008_18F7_80_size_488        1.9E+11                        \n",
       "6 20221213_0009_18F7_89_size_488        7.3E+11                        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# getting the original concentration from the text column and creating a df\n",
    "OG_concentration_df = corpus_raw %>%\n",
    "    filter(grepl(\"Original Concentration\", Text)) %>%\n",
    "    separate(Text, c(NA, \"Original Concentration\"), sep = \": \") %>%\n",
    "    separate(`Original Concentration`, c(\"Original Concentration (Particles/ mL)\", NA), sep = \"P\")\n",
    "head(OG_concentration_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1561f7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Sample Identifier</th><th scope=col>   X10</th><th scope=col>   X50</th><th scope=col>   X90</th><th scope=col> Mean</th><th scope=col>StdDev</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>20221213_0004_18F6_80_size_488</td><td>    82.5</td><td>   121.7</td><td>   183.8</td><td>    131.5</td><td>    39.9</td></tr>\n",
       "\t<tr><td>20221213_0005_18F6_90_size_488</td><td>    40.2</td><td>    66.6</td><td>   108.4</td><td>     75.2</td><td>    29.9</td></tr>\n",
       "\t<tr><td>20221213_0006_18F6_70_size_488</td><td>    99.4</td><td>   155.6</td><td>   202.1</td><td>    156.2</td><td>    42.5</td></tr>\n",
       "\t<tr><td>20221213_0007_18F7_70_size_488</td><td>    89.2</td><td>   130.6</td><td>   196.4</td><td>    139.7</td><td>    42.7</td></tr>\n",
       "\t<tr><td>20221213_0008_18F7_80_size_488</td><td>    75.9</td><td>   106.0</td><td>   149.2</td><td>    113.9</td><td>    33.7</td></tr>\n",
       "\t<tr><td>20221213_0009_18F7_89_size_488</td><td>    44.7</td><td>    70.1</td><td>   106.3</td><td>     76.8</td><td>    25.5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 6\n",
       "\\begin{tabular}{llllll}\n",
       " Sample Identifier &    X10 &    X50 &    X90 &  Mean & StdDev\\\\\n",
       " <chr> & <chr> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t 20221213\\_0004\\_18F6\\_80\\_size\\_488 &     82.5 &    121.7 &    183.8 &     131.5 &     39.9\\\\\n",
       "\t 20221213\\_0005\\_18F6\\_90\\_size\\_488 &     40.2 &     66.6 &    108.4 &      75.2 &     29.9\\\\\n",
       "\t 20221213\\_0006\\_18F6\\_70\\_size\\_488 &     99.4 &    155.6 &    202.1 &     156.2 &     42.5\\\\\n",
       "\t 20221213\\_0007\\_18F7\\_70\\_size\\_488 &     89.2 &    130.6 &    196.4 &     139.7 &     42.7\\\\\n",
       "\t 20221213\\_0008\\_18F7\\_80\\_size\\_488 &     75.9 &    106.0 &    149.2 &     113.9 &     33.7\\\\\n",
       "\t 20221213\\_0009\\_18F7\\_89\\_size\\_488 &     44.7 &     70.1 &    106.3 &      76.8 &     25.5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 6\n",
       "\n",
       "| Sample Identifier &lt;chr&gt; |    X10 &lt;chr&gt; |    X50 &lt;chr&gt; |    X90 &lt;chr&gt; |  Mean &lt;chr&gt; | StdDev &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 20221213_0004_18F6_80_size_488 |     82.5 |    121.7 |    183.8 |     131.5 |     39.9 |\n",
       "| 20221213_0005_18F6_90_size_488 |     40.2 |     66.6 |    108.4 |      75.2 |     29.9 |\n",
       "| 20221213_0006_18F6_70_size_488 |     99.4 |    155.6 |    202.1 |     156.2 |     42.5 |\n",
       "| 20221213_0007_18F7_70_size_488 |     89.2 |    130.6 |    196.4 |     139.7 |     42.7 |\n",
       "| 20221213_0008_18F7_80_size_488 |     75.9 |    106.0 |    149.2 |     113.9 |     33.7 |\n",
       "| 20221213_0009_18F7_89_size_488 |     44.7 |     70.1 |    106.3 |      76.8 |     25.5 |\n",
       "\n"
      ],
      "text/plain": [
       "  Sample Identifier                 X10      X50      X90    Mean     StdDev  \n",
       "1 20221213_0004_18F6_80_size_488     82.5    121.7    183.8     131.5     39.9\n",
       "2 20221213_0005_18F6_90_size_488     40.2     66.6    108.4      75.2     29.9\n",
       "3 20221213_0006_18F6_70_size_488     99.4    155.6    202.1     156.2     42.5\n",
       "4 20221213_0007_18F7_70_size_488     89.2    130.6    196.4     139.7     42.7\n",
       "5 20221213_0008_18F7_80_size_488     75.9    106.0    149.2     113.9     33.7\n",
       "6 20221213_0009_18F7_89_size_488     44.7     70.1    106.3      76.8     25.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# doing the same with the concentration data\n",
    "X_concentration_df = corpus_raw %>%\n",
    "    filter(grepl(\"X10\", Text)| grepl(\"X50 \", Text)| grepl(\"X90\", Text) | grepl(\"Mean\", Text)| grepl(\"StdDev\", Text)) %>%\n",
    "    separate(Text, c(\"Text\", NA), sep = \"                \") %>%\n",
    "    separate(Text, c(\"Text\", \"Concentration\"), sep = \"       \") %>%\n",
    "    pivot_wider(names_from = Text, values_from = Concentration)\n",
    "head(X_concentration_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6efb16ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22mJoining, by = \"Sample Identifier\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 7</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Sample Identifier</th><th scope=col>Original Concentration (Particles/ mL)</th><th scope=col>   X10</th><th scope=col>   X50</th><th scope=col>   X90</th><th scope=col> Mean</th><th scope=col>StdDev</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>20221213_0004_18F6_80_size_488</td><td>       3.1E+11 </td><td>    82.5</td><td>   121.7</td><td>   183.8</td><td>    131.5</td><td>    39.9</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>20221213_0005_18F6_90_size_488</td><td>       1.1E+12 </td><td>    40.2</td><td>    66.6</td><td>   108.4</td><td>     75.2</td><td>    29.9</td></tr>\n",
       "\t<tr><th scope=row>3</th><td>20221213_0006_18F6_70_size_488</td><td>       1.3E+11 </td><td>    99.4</td><td>   155.6</td><td>   202.1</td><td>    156.2</td><td>    42.5</td></tr>\n",
       "\t<tr><th scope=row>4</th><td>20221213_0007_18F7_70_size_488</td><td>       4.4E+10 </td><td>    89.2</td><td>   130.6</td><td>   196.4</td><td>    139.7</td><td>    42.7</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>20221213_0008_18F7_80_size_488</td><td>       1.9E+11 </td><td>    75.9</td><td>   106.0</td><td>   149.2</td><td>    113.9</td><td>    33.7</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>20221213_0009_18F7_89_size_488</td><td>       7.3E+11 </td><td>    44.7</td><td>    70.1</td><td>   106.3</td><td>     76.8</td><td>    25.5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 7\n",
       "\\begin{tabular}{r|lllllll}\n",
       "  & Sample Identifier & Original Concentration (Particles/ mL) &    X10 &    X50 &    X90 &  Mean & StdDev\\\\\n",
       "  & <chr> & <chr> & <chr> & <chr> & <chr> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 20221213\\_0004\\_18F6\\_80\\_size\\_488 &        3.1E+11  &     82.5 &    121.7 &    183.8 &     131.5 &     39.9\\\\\n",
       "\t2 & 20221213\\_0005\\_18F6\\_90\\_size\\_488 &        1.1E+12  &     40.2 &     66.6 &    108.4 &      75.2 &     29.9\\\\\n",
       "\t3 & 20221213\\_0006\\_18F6\\_70\\_size\\_488 &        1.3E+11  &     99.4 &    155.6 &    202.1 &     156.2 &     42.5\\\\\n",
       "\t4 & 20221213\\_0007\\_18F7\\_70\\_size\\_488 &        4.4E+10  &     89.2 &    130.6 &    196.4 &     139.7 &     42.7\\\\\n",
       "\t5 & 20221213\\_0008\\_18F7\\_80\\_size\\_488 &        1.9E+11  &     75.9 &    106.0 &    149.2 &     113.9 &     33.7\\\\\n",
       "\t6 & 20221213\\_0009\\_18F7\\_89\\_size\\_488 &        7.3E+11  &     44.7 &     70.1 &    106.3 &      76.8 &     25.5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 7\n",
       "\n",
       "| <!--/--> | Sample Identifier &lt;chr&gt; | Original Concentration (Particles/ mL) &lt;chr&gt; |    X10 &lt;chr&gt; |    X50 &lt;chr&gt; |    X90 &lt;chr&gt; |  Mean &lt;chr&gt; | StdDev &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| 1 | 20221213_0004_18F6_80_size_488 |        3.1E+11  |     82.5 |    121.7 |    183.8 |     131.5 |     39.9 |\n",
       "| 2 | 20221213_0005_18F6_90_size_488 |        1.1E+12  |     40.2 |     66.6 |    108.4 |      75.2 |     29.9 |\n",
       "| 3 | 20221213_0006_18F6_70_size_488 |        1.3E+11  |     99.4 |    155.6 |    202.1 |     156.2 |     42.5 |\n",
       "| 4 | 20221213_0007_18F7_70_size_488 |        4.4E+10  |     89.2 |    130.6 |    196.4 |     139.7 |     42.7 |\n",
       "| 5 | 20221213_0008_18F7_80_size_488 |        1.9E+11  |     75.9 |    106.0 |    149.2 |     113.9 |     33.7 |\n",
       "| 6 | 20221213_0009_18F7_89_size_488 |        7.3E+11  |     44.7 |     70.1 |    106.3 |      76.8 |     25.5 |\n",
       "\n"
      ],
      "text/plain": [
       "  Sample Identifier              Original Concentration (Particles/ mL)\n",
       "1 20221213_0004_18F6_80_size_488        3.1E+11                        \n",
       "2 20221213_0005_18F6_90_size_488        1.1E+12                        \n",
       "3 20221213_0006_18F6_70_size_488        1.3E+11                        \n",
       "4 20221213_0007_18F7_70_size_488        4.4E+10                        \n",
       "5 20221213_0008_18F7_80_size_488        1.9E+11                        \n",
       "6 20221213_0009_18F7_89_size_488        7.3E+11                        \n",
       "     X10      X50      X90    Mean     StdDev  \n",
       "1     82.5    121.7    183.8     131.5     39.9\n",
       "2     40.2     66.6    108.4      75.2     29.9\n",
       "3     99.4    155.6    202.1     156.2     42.5\n",
       "4     89.2    130.6    196.4     139.7     42.7\n",
       "5     75.9    106.0    149.2     113.9     33.7\n",
       "6     44.7     70.1    106.3      76.8     25.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combining into one final df\n",
    "final_df = full_join(OG_concentration_df, X_concentration_df)\n",
    "head(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9785a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting data\n",
    "write.csv(final_df, paste0(Output,\"/\", cur_date, \"_Final_PDF_Data.csv\"), row.names = FALSE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
